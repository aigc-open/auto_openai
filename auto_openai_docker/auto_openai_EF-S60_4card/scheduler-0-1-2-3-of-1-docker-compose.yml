services:
  scheduler-0-of-0:
    command: &id001
    - /bin/sh
    - -c
    - if [ -d /root/share_models/auto_openai/ ]; then cp -rf /root/share_models/auto_openai/auto_openai
      /app/ && python3 -m auto_openai.scheduler; else python3 -m auto_openai.scheduler;
      fi
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      GPU_TYPE: EF-S60
      LABEL: lm-server-1753761735-1134926701
      LM_SERVER_BASE_PORT: 30248
      NODE_GPU_TOTAL: '0'
    image: registry.cn-shanghai.aliyuncs.com/zhph-server/auto_openai:shdx
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes:
    - ../conf/:/app/conf
    - /root/share_models/:/root/share_models/
    - /var/run/docker.sock:/var/run/docker.sock
    - /usr/bin/docker:/usr/bin/docker
  scheduler-1-of-1:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      GPU_TYPE: EF-S60
      LABEL: lm-server-1753761735-1332417677
      LM_SERVER_BASE_PORT: 30256
      NODE_GPU_TOTAL: '1'
    image: registry.cn-shanghai.aliyuncs.com/zhph-server/auto_openai:shdx
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes:
    - ../conf/:/app/conf
    - /root/share_models/:/root/share_models/
    - /var/run/docker.sock:/var/run/docker.sock
    - /usr/bin/docker:/usr/bin/docker
  scheduler-2-of-2:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      GPU_TYPE: EF-S60
      LABEL: lm-server-1753761735-1667658105
      LM_SERVER_BASE_PORT: 30264
      NODE_GPU_TOTAL: '2'
    image: registry.cn-shanghai.aliyuncs.com/zhph-server/auto_openai:shdx
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes:
    - ../conf/:/app/conf
    - /root/share_models/:/root/share_models/
    - /var/run/docker.sock:/var/run/docker.sock
    - /usr/bin/docker:/usr/bin/docker
  scheduler-3-of-3:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      GPU_TYPE: EF-S60
      LABEL: lm-server-1753761735-251564584
      LM_SERVER_BASE_PORT: 30272
      NODE_GPU_TOTAL: '3'
    image: registry.cn-shanghai.aliyuncs.com/zhph-server/auto_openai:shdx
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes:
    - ../conf/:/app/conf
    - /root/share_models/:/root/share_models/
    - /var/run/docker.sock:/var/run/docker.sock
    - /usr/bin/docker:/usr/bin/docker
version: '3'
