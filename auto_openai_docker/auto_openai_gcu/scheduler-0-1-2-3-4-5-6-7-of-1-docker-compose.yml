services:
  scheduler-0-of-0:
    command: &id001
    - /bin/sh
    - -c
    - python3 -m auto_openai.scheduler
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      LABEL: lm-server-1734922220-543480265
      LM_SERVER_BASE_PORT: 30008
      NODE_GPU_TOTAL: '0'
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: &id002
    - ./conf/:/app/conf
    - /root/share_models/:/root/share_models/
    - /var/run/docker.sock:/var/run/docker.sock
    - /usr/bin/docker:/usr/bin/docker
  scheduler-1-of-1:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      LABEL: lm-server-1734922220-588361477
      LM_SERVER_BASE_PORT: 30016
      NODE_GPU_TOTAL: '1'
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
  scheduler-2-of-2:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      LABEL: lm-server-1734922220-113156095
      LM_SERVER_BASE_PORT: 30024
      NODE_GPU_TOTAL: '2'
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
  scheduler-3-of-3:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      LABEL: lm-server-1734922220-1614407079
      LM_SERVER_BASE_PORT: 30032
      NODE_GPU_TOTAL: '3'
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
  scheduler-4-of-4:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      LABEL: lm-server-1734922220-515226408
      LM_SERVER_BASE_PORT: 30040
      NODE_GPU_TOTAL: '4'
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
  scheduler-5-of-5:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      LABEL: lm-server-1734922220-37116246
      LM_SERVER_BASE_PORT: 30048
      NODE_GPU_TOTAL: '5'
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
  scheduler-6-of-6:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      LABEL: lm-server-1734922220-822489675
      LM_SERVER_BASE_PORT: 30056
      NODE_GPU_TOTAL: '6'
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
  scheduler-7-of-7:
    command: *id001
    environment:
      AVAILABLE_MODELS: ALL
      AVAILABLE_SERVER_TYPES: ALL
      LABEL: lm-server-1734922220-1494314721
      LM_SERVER_BASE_PORT: 30064
      NODE_GPU_TOTAL: '7'
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
version: '3'
