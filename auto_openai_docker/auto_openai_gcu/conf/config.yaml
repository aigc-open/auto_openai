REDIS_CLIENT_CONFIG:
  address: 10.12.110.149:6379
  username:
  password:
  cluster: False

OSS_CLIENT_CONFIG:
  endpoint_url: http://oss-cnsq01.cdsgss.com
  aws_access_key_id: ef55cb62ff7511edb70f46ae5a5d3b50
  aws_secret_access_key: cb78ddb9646518e554799c0f5ff1a3bd
  bucket_name: maas-1
  region_name:
#######################################################
QUEUE_TIMEOUT: 600
INFER_TIMEOUT: 600
USERFULL_TIMES_PER_MODEL: 20
UNUSERFULL_TIMES_PER_MODEL: 10
DEFAULT_MODEL_CONFIG_max_tokens: 4096
NODE_GPU_TOTAL: "4"
MOCK: false
GPU_TYPE: EF-S60
IMAGE_BASE_PATH: "harbor.uat.enflame.cc/library/enflame.cn"
AVAILABLE_MODELS: ["ALL"]
#######################################################
MODELS:
  # LLM_MODELS:
  - name: "Qwen2.5-72B-Instruct"
    server_type: vllm
    api_type: LLM
    model_max_tokens: 10240
    description: "Qwen2.5-72B-Instruct"
    need_gpu_count: 1
    template: template_qwen.jinja
    stop: ["<|im_start", "<|", "<|im_end|>", "<|endoftext|"]
    gpu_types:
      NV-A100:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 1
      EF-S60:
        need_gpu_count: 4
  - name: "Qwen2.5-Coder-14B-Instruct"
    server_type: vllm
    api_type: LLM
    model_max_tokens: 32768
    description: "Qwen2.5-Coder-14B-Instruct"
    need_gpu_count: 1
    template: template_qwen.jinja
    stop: ["<|im_start", "<|", "<|im_end|>", "<|endoftext|"]
    gpu_types:
      NV-A100:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 1
      EF-S60:
        need_gpu_count: 2
  - name: "Qwen2.5-Coder-14B-Instruct-10k"
    server_type: vllm
    api_type: LLM
    model_max_tokens: 10240
    description: "Qwen2.5-Coder-14B-Instruct-10k"
    need_gpu_count: 1
    template: template_qwen.jinja
    stop: ["<|im_start", "<|", "<|im_end|>", "<|endoftext|"]
    gpu_types:
      NV-A100:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 1
      EF-S60:
        need_gpu_count: 2
  - name: "Qwen2.5-32B-Instruct-GPTQ-Int4"
    server_type: vllm
    api_type: LLM
    model_max_tokens: 32768
    description: "Qwen2.5-32B-Instruct-GPTQ-Int4"
    need_gpu_count: 1
    template: template_qwen.jinja
    stop: ["<|im_start", "<|", "<|im_end|>", "<|endoftext|"]
    quantization: gptq
    gpu_types:
      NV-A100:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 1
      EF-S60:
        need_gpu_count: 1
  - name: "Qwen2.5-7B-Instruct"
    server_type: vllm
    api_type: LLM
    model_max_tokens: 32768
    description: "Qwen2.5-7B-Instruct"
    need_gpu_count: 1
    template: template_qwen.jinja
    stop: ["<|im_start", "<|", "<|im_end|>", "<|endoftext|"]
    gpu_types:
      NV-A100:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 2
      EF-S60:
        need_gpu_count: 1
  - name: "Qwen2.5-Coder-7B-Instruct"
    server_type: vllm
    api_type: LLM
    model_max_tokens: 32768
    description: "Qwen2.5-Coder-7B-Instruct"
    need_gpu_count: 1
    template: template_qwen.jinja
    stop: ["<|im_start", "<|", "<|im_end|>", "<|endoftext|"]
    gpu_types:
      NV-A100:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 2
      EF-S60:
        need_gpu_count: 1
  - name: "codegeex4-all-9b"
    server_type: vllm
    api_type: LLM
    model_max_tokens: 131072
    description: "codegeex4-all-9b"
    need_gpu_count: 1
    template: template_glm4.jinja
    stop: ["<|user|>", "<|assistant|>"]
    gpu_types:
      NV-A100:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 2
      EF-S60:
        need_gpu_count: 1
  - name: "glm-4-9b-chat"
    server_type: vllm
    api_type: LLM
    model_max_tokens: 131072
    description: "glm-4-9b-chat"
    need_gpu_count: 1
    template: template_glm4.jinja
    stop: ["<|user|>", "<|assistant|>"]
    gpu_types:
      NV-A100:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 2
      EF-S60:
        need_gpu_count: 1

  # VISION_MODELS:
  - name: "glm-4v-9b"
    server_type: llm-transformer-server
    api_type: VLLM
    model_max_tokens: 8192
    description: "glm-4v-9b"
    need_gpu_count: 1
    template: template_glm4.jinja
    stop: []
    gpu_types:
      NV-A100:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 1
      EF-S60:
        need_gpu_count: 1
