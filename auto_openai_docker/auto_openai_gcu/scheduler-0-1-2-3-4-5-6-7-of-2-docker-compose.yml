services:
  scheduler-0_1:
    command: &id001
    - /bin/sh
    - -c
    - python3 -m auto_openai.scheduler
    environment:
      LABEL: lm-server-1734700534
      LM_SERVER_BASE_PORT: 30072
      NODE_GPU_TOTAL: 0,1
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: &id002
    - ./conf/:/app/conf
    - /root/share_models/:/root/share_models/
    - /var/run/docker.sock:/var/run/docker.sock
    - /usr/bin/docker:/usr/bin/docker
  scheduler-2_3:
    command: *id001
    environment:
      LABEL: lm-server-1734700535
      LM_SERVER_BASE_PORT: 30080
      NODE_GPU_TOTAL: 2,3
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
  scheduler-4_5:
    command: *id001
    environment:
      LABEL: lm-server-1734700536
      LM_SERVER_BASE_PORT: 30088
      NODE_GPU_TOTAL: 4,5
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
  scheduler-6_7:
    command: *id001
    environment:
      LABEL: lm-server-1734700537
      LM_SERVER_BASE_PORT: 30096
      NODE_GPU_TOTAL: 6,7
    image: harbor.uat.enflame.cc/library/enflame.cn/auto_openai:0.2
    network_mode: host
    privileged: true
    restart: always
    shm_size: 8gb
    volumes: *id002
version: '3'
