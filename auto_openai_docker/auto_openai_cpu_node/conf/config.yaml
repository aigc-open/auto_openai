REDIS_CLIENT_CONFIG:
  address: 10.12.110.149:6379
  username:
  password:
  cluster: False

OSS_CLIENT_CONFIG:
  endpoint_url: https://boto3.cpolar.cn
  aws_access_key_id: admin
  aws_secret_access_key: admin123
  bucket_name: api-platform
  region_name:
#######################################################
QUEUE_TIMEOUT: 600
INFER_TIMEOUT: 600
USERFULL_TIMES_PER_MODEL: 20
UNUSERFULL_TIMES_PER_MODEL: 10
DEFAULT_MODEL_CONFIG_max_tokens: 4096
NODE_GPU_TOTAL: "4"
MOCK: false
GPU_TYPE: CPU
IMAGE_BASE_PATH: "registry.cn-shanghai.aliyuncs.com/zhph-server"
#######################################################
CUSTOM_MODLES:
  - name: AI仿真大模型
    server_type: vllm
    api_type: LLM
    model_max_tokens: 10240
    description: "AI仿真大模型"
    need_gpu_count: 1
    template: template_qwen.jinja
    stop: ["<|im_start", "<|", "<|im_end|>", "<|endoftext|"]
    gpu_types:
      EF-S60:
        need_gpu_count: 1
      NV-A100-40G:
        need_gpu_count: 1
      NV-A100-80G:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 1
      NV-A30:
        need_gpu_count: 1
      NV-3090:
        need_gpu_count: 1
      NV-3060:
        need_gpu_count: 1
      NV-T4-16G:
        need_gpu_count: 1
      NV-P40:
        need_gpu_count: 1
      NV-4060:
        need_gpu_count: 1
      CPU:
        need_gpu_count: 1
  - name: 石油大模型
    server_type: vllm
    api_type: LLM
    model_max_tokens: 10240
    description: "石油大模型"
    need_gpu_count: 1
    template: template_qwen.jinja
    stop: ["<|im_start", "<|", "<|im_end|>", "<|endoftext|"]
    gpu_types:
      EF-S60:
        need_gpu_count: 1
      NV-A100-40G:
        need_gpu_count: 1
      NV-A100-80G:
        need_gpu_count: 1
      NV-4090:
        need_gpu_count: 1
      NV-A30:
        need_gpu_count: 1
      NV-3090:
        need_gpu_count: 1
      NV-3060:
        need_gpu_count: 1
      NV-T4-16G:
        need_gpu_count: 1
      NV-P40:
        need_gpu_count: 1
      NV-4060:
        need_gpu_count: 1
      CPU:
        need_gpu_count: 1
 